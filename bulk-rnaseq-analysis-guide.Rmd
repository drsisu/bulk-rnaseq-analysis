---
title: "Bulk RNA-seq data processing and differential gene expression analysis pipeline"
author: Erick Lu
output: 
  html_document:
    toc: true
---

## Introduction

Here, I present a complete bulk RNA-sequencing pipeline, including:

1. Finding and downloading the raw data using SRA tools
2. Mapping FASTQ files using STAR
3. Differential gene analysis using DESeq2
4. Visualizations for Bulk RNA-sequencing


## Obtaining the raw data

### Data repository at GSE106305

The raw data is available at: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE106305. There are several samples associated with this study, and we will only be focusing on the following samples:

Sample Name | GSM Identifier | SRA Identifier (SRX) | SRA Runs (SRR, download these)
------------------ | ----------------- | -------------------------- | --------------------------------------------------------
LNCaP_RNA-Seq_Empty_Vector_Normoxia_rep1 | GSM3145509 | SRX4096735 | SRR7179504, SRR7179505, SRR7179506, and SRR7179507
LNCaP_RNA-Seq_Empty_Vector_Normoxia_rep2 | GSM3145510 | SRX4096736 | SRR7179508, SRR7179509, SRR7179510, and SRR7179511
LNCaP_RNA-Seq_Empty_Vector_Hypoxia_rep1 | GSM3145513 | SRX4096739 | SRR7179520, SRR7179521, SRR7179522, and SRR7179523
LNCaP_RNA-Seq_Empty_Vector_Hypoxia_rep2 | GSM3145514 | SRX4096740 | SRR7179524, SRR7179525, SRR7179526, and SRR7179527
PC3_RNA-Seq_siCtrl_Normoxia_rep1 | GSM3145517 | SRX4096743 | SRR7179536
PC3_RNA-Seq_siCtrl_Normoxia_rep2 | GSM3145518 | SRX4096744 | SRR7179537
PC3_RNA-Seq_siCtrl_Hypoxia_rep1 | GSM3145521 | SRX4096747 | SRR7179540
PC3_RNA-Seq_siCtrl_Hypoxia_rep2 | GSM3145522 | SRX4096748 | SRR7179541

We have selected the control samples for both cell lines (Empty Vector for LNCaP and siCtrl for PC3) in conditions of either normoxia or hypoxia. This will allow us to analyze the LNCaP and PC3 cell lines for their gene expression changes in response to hypoxia, and compare which pathways are commonly upregulated/downregulated by both lines.

Each of the samples above have an associated SRA accession number, indicated above. These SRA accessions are used to download the raw sequencing data. To eventually get the raw data in FASTQ format, we first need to first download the SRA files (`.sra`) associated with each sample.

### Downloading FASTQ files using SRA toolkit

In order to download the SRA files onto your machine, we use the NCBI's SRA toolkit, which lets us use the command line to download a specified SRA accession ID. You can read more about SRA toolkit here: https://www.ncbi.nlm.nih.gov/books/NBK242621/.

The toolkit works by first using the `prefetch` command to download the SRA file associated with the specified SRA ID. The SRA file contains a set of "instructions" for downloading the sequencing data associated with the SRA ID from NCBI. A sample command would be: `prefetch SRR7179504`. This will download the file `SRR7179504.sra` into your home directory at ~/ncbi/public/sra/.

After you have downloaded the SRA file, you can use `fastq-dump` to extract the contents of it into a `.fastq` file. The Edwards lab at SDSU provides a nice tutorial for how to use fastq-dump here: https://edwards.sdsu.edu/research/fastq-dump/. A sample command would be: 

```bash
fastq-dump --outdir fastq --gzip --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip ~/ncbi/public/sra/SRR7179504.sra
```

Since there are lots of SRA files associated with our samples, it would take a long time to manually run `prefetch` and `fastq-dump` for all the files. To automate all the downloads, I wrote a small script in python to call `fastq-dump` on each of the SRA IDs we want. The code is shown below as well as provided in this repo as `fastq_download.py`:

```py
import subprocess

sra_numbers = [
    "SRR7179504", "SRR7179505", "SRR7179506", "SRR7179507",
    "SRR7179508", "SRR7179509", "SRR7179510", "SRR7179511",
    "SRR7179520", "SRR7179521", "SRR7179522", "SRR7179523",
    "SRR7179524", "SRR7179525", "SRR7179526", "SRR7179527",
    "SRR7179536", "SRR7179537", "SRR7179540","SRR7179541"
    ]

# this will download the .sra files to ~/ncbi/public/sra/ (will create directory if not present)
for sra_id in sra_numbers:
    print ("Currently downloading: " + sra_id)
    prefetch = "prefetch " + sra_id
    print ("The command used was: " + prefetch)
    subprocess.call(prefetch, shell=True)

# this will extract the .sra files from above into a folder named 'fastq'
for sra_id in sra_numbers:
    print ("Generating fastq for: " + sra_id)
    fastq_dump = "fastq-dump --outdir fastq --gzip --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip ~/ncbi/public/sra/" + sra_id + ".sra"
    print ("The command used was: " + fastq_dump)
    subprocess.call(fastq_dump, shell=True)
```

We can run the python script by simply navigating to the folder on your machine where you want to store the fastq files (via the command line), then running `python fastq_download.py`. This should work in python 2 and python 3. After running the python script, our .fastq files should all be sitting in a directory called 'fastq'.

### Concatenating FASTQ files

For samples such as LNCaP_RNA-Seq_Empty_Vector_Normoxia_rep1, there are four resulting fastq files containing the sequencing data. We can concatenate these four files into one file by using `cat` in the command line and storing the output into a new fastq file. Below, I perform the concatenation for each of the LNCaP samples, and :

```bash
cat SRR7179504_pass.fastq.gz SRR7179505_pass.fastq.gz SRR7179506_pass.fastq.gz SRR7179507_pass.fastq.gz  > LNCAP_Normoxia_S1.fastq.gz
cat SRR7179508_pass.fastq.gz SRR7179509_pass.fastq.gz SRR7179510_pass.fastq.gz SRR7179511_pass.fastq.gz  > LNCAP_Normoxia_S2.fastq.gz
cat SRR7179520_pass.fastq.gz SRR7179521_pass.fastq.gz SRR7179522_pass.fastq.gz SRR7179523_pass.fastq.gz  > LNCAP_Hypoxia_S1.fastq.gz
cat SRR7179524_pass.fastq.gz SRR7179525_pass.fastq.gz SRR7179526_pass.fastq.gz SRR7179527_pass.fastq.gz  > LNCAP_Hypoxia_S2.fastq.gz
```

In contrast, there is only one fastq file for each of the PC3 samples. We can just rename them from their SRR identifiers to their real sample names using `mv`:

```bash
mv SRR7179536_pass.fastq.gz PC3_Normoxia_S1.fastq.gz
mv SRR7179537_pass.fastq.gz PC3_Normoxia_S2.fastq.gz
mv SRR7179540_pass.fastq.gz PC3_Hypoxia_S1.fastq.gz
mv SRR7179541_pass.fastq.gz PC3_Hypoxia_S2.fastq.gz
```

## Aligning reads using STAR

Each read in your fastq file must be "mapped" to a reference genome. Mapping can be described as finding the place in the reference genome that best matches the fragment of an mRNA transcript captured in the read. In this section, I will describe the concepts behind mapping reads to a reference genome, and how to do it using the tool STAR and some python scripting.

### The concepts behind mapping reads

In order to perform bulk RNA-sequencing, a "library" must first be prepared from the cells of interest and this library is what is sequenced to create the fastq files. To create a library, mRNA from the cells is captured and reverse transcribed into cDNA. This is then fragmented into small pieces, and sequencing adaptors are ligated to the ends of each fragment to create the "library". The resulting fastq file contains the sequences of all these tiny little fragments. Using the sequence for each fragment (a "read"), we can then try to figure out from which part of the genome that fragment came from, and subsequently which gene was being transcribed to create the original mRNA that was captured. Counting the number of times a "read" mapped to a specific gene gives us information about how "high" or "low" a gene was being expressed.

### STAR

A great RNA-seq alignment tool is STAR (Spliced Transcripts Alignment to a Reference, https://github.com/alexdobin/STAR). In order to install STAR, follow the installation instructions provided in the github repo for the platform you are using.

#### building human genome index using genomeGenerate

Once STAR is installed, we first need to build a genome index. In our case, we need to use the human reference genome since we are analyzing RNA-seq data from human cells. We have to supply STAR with the human reference genome sequence (FASTA) and annotation (GTF) files, from which STAR will make genome index files.

We can download the FASTA and GTF files from the ensembl website (https://uswest.ensembl.org/Homo_sapiens/Info/Index) or using the command line:

```bash
wget ftp://ftp.ensembl.org/pub/release-99/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz
wget ftp://ftp.ensembl.org/pub/release-99/gtf/homo_sapiens/Homo_sapiens.GRCh38.99.gtf.gz
gunzip *.gz
```

Once these are downloaded and unzipped, we can run the STAR genomeGenerate command below to make the genome index file. For the genomeDir parameter, you can specify the directory where you are keeping the FASTA and GTF files.

```bash
STAR --runThreadN 64 --runMode genomeGenerate --genomeDir /data/genomes/h38/STAR/ --genomeFastaFiles /data/genomes/h38/STAR/Homo_sapiens.GRCh38.dna.primary_assembly.fa --sjdbGTFfile /data/genomes/h38/STAR/Homo_sapiens.GRCh38.99.gtf
```

The output from successfully running the command looks like:

```{}
Feb 15 20:06:34 ..... started STAR run
Feb 15 20:06:34 ... starting to generate Genome files
Feb 15 20:07:28 ... starting to sort Suffix Array. This may take a long time...
Feb 15 20:07:41 ... sorting Suffix Array chunks and saving them to disk...
Feb 15 20:20:11 ... loading chunks from disk, packing SA...
Feb 15 20:21:15 ... finished generating suffix array
Feb 15 20:21:15 ... generating Suffix Array index
Feb 15 20:25:16 ... completed Suffix Array index
Feb 15 20:25:16 ..... processing annotations GTF
Feb 15 20:25:26 ..... inserting junctions into the genome indices
Feb 15 20:27:58 ... writing Genome to disk ...
Feb 15 20:28:01 ... writing Suffix Array to disk ...
Feb 15 20:28:18 ... writing SAindex to disk
Feb 15 20:28:20 ..... finished successfully
```

After running the command, you should see a bunch of genome index files in the directory specified by genomeDir. Now, we can start mapping reads from our FASTQ files, which I will explain in the next section.

#### mapping reads

An example STAR command used to map a single sample, LNCAP_Normoxia_S1_R1_001.fastq.gz, to the reference genome that we just built is:

```bash
STAR --runThreadN 64 --genomeDir /data/genomes/h38/STAR --outFilterType BySJout --outFilterMismatchNoverLmax 0.04 --outFilterMismatchNmax 999 --alignSJDBoverhangMin 1 --alignSJoverhangMin 8 --outFilterMultimapNmax 20 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --readFilesIn /fastq/LNCAP_Normoxia_S1_R1_001.fastq.gz --clip3pAdapterSeq GATCGGAAGAGCACACGTCTGAACTCCAGTCAC --outSAMtype BAM SortedByCoordinate --quantMode GeneCounts --outFileNamePrefix LNCAP_Normoxia_S1
```
Notice that I've plugged in the directory that contains the genome index files for `--genomeDir`, as well as the fastq file location for sample LNCAP_Normoxia_S1_R1_001.fastq.gz for `--readFilesIn` and also provided the sample name for `--outFileNamePrefix`.


Since we have 8 samples to run, and each sample will take a while to run, we can use a python script to run the command for each fastq in the directory:

```py
import subprocess
import os

# modify these variables based on where you store your data / genome index
output_directory = "STAR_output/"
genome_directory = "/data/genomes/h38/STAR/"
fastq_directory = "/data/analysis/hypoxia/fastq/"

os.mkdir(output_directory)
for fastq in os.listdir(fastq_directory):
    # only process files that end in fastq.gz
    if fastq.endswith('.fastq.gz'):
        prefix=fastq.strip(".fastq.gz") + "_output"
        # make an output folder for the current fastq file
        os.mkdir(output_directory + prefix)
        print ("Currently mapping: " + fastq)
        # run STAR on the current fastq file
        subprocess.call("STAR --runThreadN 64 --genomeDir " + genome_directory + " --readFilesCommand zcat --outFilterType BySJout --outFilterMismatchNoverLmax 0.04 --outFilterMismatchNmax 999 --alignSJDBoverhangMin 1 --alignSJoverhangMin 8 --outFilterMultimapNmax 20 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --readFilesIn "+ fastq_directory + fastq + " --clip3pAdapterSeq GATCGGAAGAGCACACGTCTGAACTCCAGTCAC --outSAMtype BAM SortedByCoordinate --quantMode GeneCounts --outFileNamePrefix " + output_directory + prefix + "/", shell=True)
```

The output of a successful STAR alignment looks like this, for one iteration of the loop:

```{}
Currently mapping: PC3_Normoxia_S1.fastq.gz
Feb 16 23:28:42 ..... started STAR run
Feb 16 23:28:42 ..... loading genome
Feb 16 23:28:59 ..... started mapping
Feb 16 23:31:07 ..... finished mapping
Feb 16 23:31:10 ..... started sorting BAM
Feb 16 23:32:59 ..... finished successfully
```

We can save the script as align_STAR.py, and run the script by simply typing `python align_STAR.py` in the command line (should work in python 2 or 3). The output containing the alignment files can be found in the folder `STAR_output`.

### Understanding ReadsPerGene.out.tab

In the STAR_output folder, you will find a folder of results for each one of the FASTQ files you mapped. Inside each folder, you will find: 

```{}
Aligned.sortedByCoord.out.bam
Log.final.out
Log.out
Log.progress.out
ReadsPerGene.out.tab
SJ.out.tab
```

The file that contains the data you need is `ReadsPerGene.out.tab`. This file contains the number of reads that mapped to each gene in the transcriptome. A quick glance at the file using the command below shows the structure of the file, in which there are some QC metrics at the beginning of the file (N_unmapped, etc.) followed by each gene in the transcriptome. 

```ba
cat ReadsPerGene.out.tab | head -n 10
```

```{}
N_unmapped	2461926	2461926	2461926
N_multimapping	4255262	4255262	4255262
N_noFeature	4048236	41792820	4475290
N_ambiguous	3081395	50727	1691846
ENSG00000223972	0	0	0
ENSG00000227232	3	0	3
ENSG00000278267	13	0	13
ENSG00000243485	0	0	0
ENSG00000284332	0	0	0
ENSG00000237613	0	0	0
```

The first column corresponds to the ensembl gene ID, and columns 2, 3, and 4 correspond to the counts mapped for each gene. You might be wondering why there are 3 columns of counts-- each column corresponds to the "strandedness" of the read mapping. An RNA-seq library is composed of DNA, which has two strands: a "sense" strand and an "anti-sense" strand. RNA-sequencing libraries can be prepared as either "unstranded" or "stranded". The column you choose for downstream analysis is typically dictated by the type of library kit that was used to prepare the samples.

* If an "unstranded" library prep kit was used, column 2 should be selected. In this case, we don't know which strand the original mRNA was produced from, and reads are mapped to both the sense and anti-sense strand.

* If a "stranded" library prep kit was used, we must choose from column 3 or 4. The information from which strand the mRNA originated from is retained. Column 3 corresponds to the first read strand aligned, and column 4 corresponds to the second read strand aligned.

Looking at the sample information at https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3145522, we see that the TruSeq® Stranded mRNA Library Prep Kit (RS-122-2101, Illumina) was used to prepare the samples. Since this is a stranded library prep kit, we must select from column 3 or 4. Looking at the output, we observe that column 4 contains the reads whereas column 3 does not. We will proceed with using column 4 from each of the samples for downstream analysis.

### combining read counts from each sample

There is an folder for each one of our samples. We need to combine column 4 in `ReadsPerGene.out.tab` for each of the samples into one data file. To do so, we can loop through each of the `ReadsPerGene.out.tab` files in Python and extract information from the column corresponding to the correct strand using the code below.

```py
import os
import csv

# modify desired_column based on strandedness of library kit
desired_column = 3
output_directory = "STAR_output/"
sample_dict = {}
sample_names = []

# loop through each folder and store data from ReadsPerGene.out.tab in sample_dict
for folder in os.listdir(output_directory):
    if folder.endswith("_output"):
        file_name=folder.strip('_output')
        sample_names.append(file_name)
        gene_dict = {}
        with open(output_directory + folder + "/ReadsPerGene.out.tab") as tabfile:
            print("Column " + str(desired_column) + " of " + file_name + " stored")
            reader = csv.reader(tabfile, delimiter = "\t")
            for row in reader:
                gene_dict[row[0]]=row[desired_column]
        # store gene_dict for the current file in sample_dict
        sample_dict[file_name] = gene_dict

# write sample_dict to output files
# the qc metrics are stored in qc.csv, and the gene counts are stored in raw_counts.csv
with open("raw_counts.csv", "wt") as counts_file, open("qc.csv", "wt") as qc_file:
    counts_writer = csv.writer(counts_file)
    qc_writer = csv.writer(qc_file)
    counts_writer.writerow( ['ensembl_id']+ sample_names )
    qc_writer.writerow( ['qc_metric']+ sample_names )
    sorted_genes = sorted(list(sample_dict[sample_names[0]].keys()))
    for gene in sorted_genes:
        output=[gene]
        for sample in sample_names:
            output.append(sample_dict[sample][gene])
        if gene.startswith("N_"):
            qc_writer.writerow(output)
        else:
            counts_writer.writerow(output)
```

The code outputs a file called `raw_counts.csv`, with 9 columns. The first column is the Ensembl ID of each of the genes in the transcriptome. The rest of the columns correspond to the counts per gene for the 8 samples. Another file named `qc.csv` is created containing the qc metrics that were at the beginning of the `ReadsPerGene.out.tab` file for each sample.

## Performing Differential Gene Expression Analysis

DESeq2 explanation: in order to perform differential gene analysis using the R package DESeq2, from bioconductor. 

A great tutorial that goes into the nitty-gritty details of this analysis can be found here: https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html. My analysis below is an example of the workflow that a scientist would use to analyze their RNA-seq data.

Installing DESeq2:

```{r eval=F}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("DESeq2")
```

### Loading data and packages

```{r}
library("DESeq2")
library("tidyverse")
```

We can now load `raw_counts.csv` into R, and take a look at the structure of the data

```{r}
data <- read.csv("raw_counts.csv", header = T)
data <- data[,sort(colnames(data))]
head(data)
```

```{r}
dim(data)
```

We observe that there are 60676 rows and 9 columns to the data, in which each row is a gene and each column corresponds to the reads per gene for each sample. This is the format that is appropriate for the DESeq2 package. It would be nice to have each Ensembl ID translated into its gene name. We can build an annotation file using the BioMart at ensembl.org, which I'll explain in the following section.

### Making an annotation file from BioMart

A genome annotation file wil let us map ensembl IDs to their gene names. To build one:

1. First go to the ensembl BioMart at http://uswest.ensembl.org/biomart/martview/
2. Choose the database to use, in this case "Ensembl Genes 99" or whatever is the current version
3. Choose an annotation to use, in this case "Human Genes (GRCh38.p13) 
4. On the left sidebar, click "Attributes", which will allow you to select the items you want to map. The items you want are "Gene stable ID", (which is the ensemble id in our raw_counts.csv file), and "Gene name". You can un-check "Gene stable ID version", "Transcript stable ID", and "Transcript stable ID version". You can also choose to include other attributes of your liking, such as "Gene type" to know which genes are protein-coding. If we want to perform Gene Set Enrichment Analysis (GSEA) downstream, we will need this category.
5. Click on results, check "unique results only", select export as csv, and hit the "Go" button!

The annotation should download to your computer as "mart_export.txt". We can rename it to "GRCh38.p13_annotation.csv" read it into R:

```{r}
human_annotation <- read.csv("GRCh38.p13_annotation.csv", header = T, stringsAsFactors = F)
head(human_annotation)
```

We observe that there are two columns, one named "Gene.stable.ID" which is contains the ensembl IDs, and a second column named "Gene.name" which contains the gene names that we want to map to our `raw_counts.csv` file. To map the names, we can join the two tables based on the ensembl IDs using the `right_join()` function from the tidyverse.

```{r}
annotated_data <- right_join(human_annotation, data, by = c("Gene.stable.ID" = "ensembl_id"))
annotated_data
write.csv(annotated_data, file = "gene_annotated_raw_counts.csv")
```

### Creating the DESeq2 object

To create the DESeq2 object, we can use the function `DESeqDataSetFromMatrix`, which requires three items:

1. countData - The data in the form of an integer matrix, in which the rownames correspond to the gene IDs. 
2. colData - A table that provides the sample groups and identifies which samples fall in each group (i.e. biological replicates).
3. design - A formula that expressed how the counts for each gene depend on the variables in colData. Typically if you are just comparing between groups, we can use the groups defined in colData.

```{r}
# make a counts matrix in which rownames are ensembl ids
my_countData <- column_to_rownames(data, "ensembl_id")

# identify biological replicates
condition <- c(rep("LNCAP_Hypoxia", 2), rep("LNCAP_Normoxia", 2), rep("PC3_Hypoxia", 2), rep("PC3_Normoxia", 2))

# assign replicates to each sample name
my_colData <- as.data.frame(condition)
rownames(my_colData) <- colnames(data[,-1])
my_colData
```

Now that we have these the required inputs, we can run `DESeqDataSetFromMatrix`

```{r}
dds <- DESeqDataSetFromMatrix(countData = my_countData,
							  colData = my_colData,
							  design = ~condition)
```

This can immediately be processed using the `DESeq()`, which will perform differential expression analysis based on a negative binomial distribution. From the documentation, this function will perform:

1. estimation of size factors: estimateSizeFactors
2. estimation of dispersion: estimateDispersions
3. Negative Binomial GLM fitting and Wald statistics: nbinomWaldTest

More information about what goes into this processing step can be found here: https://www.bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html

```{r}
dds <- DESeq(dds)
```

We can observe some basic information about the dds object just by calling its name:

```{r}
dds
```

We can also sift through the dds object using `@` and `$`. For example, we can find the raw counts data that was used to create the dds object at:

```{r}
head(dds@assays$data@listData$counts)
```

## Visualizations: sample variability

At this point, we can start to assess sample to sample variability. DESeq2 has some built-in functions that can be used to do so, including distance plots and PCA plots. In order to use these functions, we first perform a variance stabilizing transformation on the data using `vst()`:

```{r}
vsd <- vst(dds, blind = TRUE)
```

We can plug the variance stabilized object into the following functions:

### 1. Distance Plot

```{r}
plotDists = function (vsd.obj) {
  sampleDists <- dist(t(assay(vsd.obj)))
  sampleDistMatrix <- as.matrix( sampleDists )
  rownames(sampleDistMatrix) <- paste( vsd.obj$condition )
  colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)
  pheatmap(sampleDistMatrix,
           clustering_distance_rows = sampleDists,
           clustering_distance_cols = sampleDists,
           col = colors)
}
plotDists(vsd)
```

### 2. PCA Plot

```{r}
name.plotPCA = function (vsd.obj) {
  pcaData <- plotPCA(vsd.obj,  intgroup = c("condition"), returnData = T)
  percentVar <- round(100 * attr(pcaData, "percentVar"))
  ggplot(pcaData, aes(PC1, PC2, color=condition)) +
    geom_point(size=3) +
    labs(x = paste0("PC1: ",percentVar[1],"% variance"),
         y = paste0("PC2: ",percentVar[2],"% variance"),
         title = "PCA Plot colored by condition") +
    geom_text_repel(aes(label = name), color = "black")
}

name.plotPCA(vsd)
```

### 3. Variable Genes Heatmap

```{r}

vsd.obj = lncap_vsd

plotHeatmap <- function (vsd.obj, num_genes = 500, annotation) {
  brewer_palette <- "RdBu"
  # Ramp the color in order to get the scale.
  ramp <- colorRampPalette(brewer.pal(11, brewer_palette))
  mr <- ramp(256)[256:1]
  # get the stabilized counts from the vsd object
  stabilized_counts <- assay(vsd.obj)
  # calculate the variances by row(gene) to find out which genes are the most variable across the samples.
  row_variances <- rowVars(stabilized_counts)
  # get the top most variable genes
  top_variable_genes <- stabilized_counts[order(row_variances, decreasing=T)[1:num_genes],]
  # subtract out the means from each row, leaving the variances for each gene
  top_variable_genes <- top_variable_genes - rowMeans(top_variable_genes, na.rm=T)
  # replace the ensembl ids with the gene names
  gene_names <- annotation$Gene.name[match(rownames(top_variable_genes), annotation$Gene.stable.ID)]
  rownames(top_variable_genes) <- gene_names
  # reconstruct colData without sizeFactors for heatmap labeling
  coldata <- as.data.frame(vsd.obj@colData)
  coldata$sizeFactor <- NULL
  # draw heatmap using pheatmap
  my_heatmap <- pheatmap(top_variable_genes, color = mr, annotation_col = coldata, fontsize_col = 5, fontsize_row = 250/num_genes, fontsize = 5, border_color = NA)
  my_heatmap
}

plotHeatmap(vsd, annotation = human_annotation)
plotHeatmap(vsd, num_genes = 30, annotation = human_annotation)
plotHeatmap(vsd, num_genes = 100, annotation = human_annotation)

```

### Create individual dds objects

Because a lot of the variability in the data is due to the cell line difference, and because the biological comparisons that we want to make are only within either LNCaP, we will create an individual dds object for just LNCaP samples and and just the PC3 samples. The function generate_DESeq_object() below will make a dds object using your raw counts data and the groups that you want to compare. So far, this function can only do groups of 2. It will select the columns out from the raw data that match the group designations using `grep()`, build the colData matrix based on your group designations and the samples it selected, then generate and process the dds object using `DESeqDataSetFromMatrix()` and `DESeq()`.

```{r}
generate_DESeq_object <- function (my_data, groups) {
  my_data <- column_to_rownames(my_data, "ensembl_id")
  data_subset1 <- my_data[,grep(str_c("^", groups[1]), colnames(my_data))]
  data_subset2 <- my_data[,grep(str_c("^", groups[2]), colnames(my_data))]
  my_countData <- cbind(data_subset1, data_subset2)
  condition <- c(rep(groups[1],ncol(data_subset1)), rep(groups[2],ncol(data_subset2)))
  my_colData <- as.data.frame(condition)
  rownames(my_colData) <- colnames(my_countData)
  print(my_colData)
  dds <- DESeqDataSetFromMatrix(countData = my_countData,
  							  colData = my_colData,
  							  design = ~ condition)
  dds <- DESeq(dds)
  return(dds)
}

lncap <- generate_DESeq_object(data, c("LNCAP_Hypoxia", "LNCAP_Normoxia"))
pc3 <- generate_DESeq_object(data, c("PC3_Hypoxia", "PC3_Normoxia"))
```

We can double check to make sure that the appropriate columns have been selected and that the colData is correct.

```{r}
lncap@colData
head(lncap@assays$data@listData$counts)
```

```{r}
lncap_vsd <- vst(lncap, blind = T)
pc3_vsd <- vst(pc3, blind = T)
```

```{r}
plotHeatmap(lncap_vsd, 50, annotation = human_annotation)
plotHeatmap(pc3_vsd, 50, annotation = human_annotation)
```



### extract results from dds object

```{r}
generate_DE_results <- function (dds, comparisons, fdrcutoff = 0.001, rawpcutoff = 0.001, log2cutoff = 0.5, cpmcutoff = 2) {
  # generate average counts per million metric from raw count data 
  raw_counts <- counts(dds, normalized = F)
  cpms <- enframe(rowMeans(cpm(raw_counts)))
  colnames(cpms) <- c("ensembl_id", "avg_cpm")
  
  # extract DESeq results between the comparisons indicated
  res <- results(dds, contrast = c("condition", comparisons[1], comparisons[2]))[,-c(3,4)]
  
  # annotate the data with gene name and average counts per million value
  res <- as_tibble(res, rownames = "ensembl_id")
  # read in the annotation and append it to the data
  my_annotation <- read.csv("GRCh38.p13_annotation.csv", header = T, stringsAsFactors = F)
  res <- left_join(res, my_annotation, by = c("ensembl_id" = "Gene.stable.ID"))
  # append the average cpm value to the results data
  res <- left_join(res, cpms, by = c("ensembl_id" = "ensembl_id"))
  
  # combine normalized counts with entire DE list
  normalized_counts <- round(counts(dds, normalized = TRUE),3)
  pattern <- str_c(comparisons[1], "|", comparisons[2])
  combined_data <- as_tibble(cbind(res, normalized_counts[,grep(pattern, colnames(normalized_counts))] ))
  combined_data <- combined_data[order(combined_data$log2FoldChange, decreasing = T),]
  
  # make ordered rank file for GSEA, selecting only protein coding genes
  res_prot <- res[which(res$Gene.type == "protein_coding"),]
  res_prot_ranked <- res_prot[order(res_prot$log2FoldChange, decreasing = T),c("Gene.name", "log2FoldChange")]
  res_prot_ranked <- na.omit(res_prot_ranked)
  res_prot_ranked$Gene.name <- str_to_upper(res_prot_ranked$Gene.name)
  
  # generate sorted lists with the indicated cutoff values
  res <- res[order(res$log2FoldChange, decreasing=TRUE ),]
  de_genes_fdr <- res[which(res$padj < fdrcutoff),]
  de_genes_rawp <- res[which(res$pvalue < rawpcutoff),]
  de_genes_log2f <- res[which(abs(res$log2FoldChange) > log2cutoff & res$padj < fdrcutoff),]
  de_genes_cpm <- res[which(res$avg_cpm > cpmcutoff & res$padj < fdrcutoff),]
  
  # write output to files
  write.csv (de_genes_fdr, file = paste0(comparisons[1], "_vs_", comparisons[2], "_fdrgenes.csv"), row.names =F)
  write.csv (de_genes_rawp, file = paste0(comparisons[1], "_vs_", comparisons[2], "_rawpgenes.csv"), row.names =F)
  write.csv (de_genes_log2f, file = paste0(comparisons[1], "_vs_", comparisons[2], "_log2f.csv"), row.names =F)
  write.csv (de_genes_cpm, file = paste0(comparisons[1], "_vs_", comparisons[2], "_cpm_cutoff.csv"), row.names =F)
  write.csv (combined_data, file = paste0(comparisons[1], "_vs_", comparisons[2], "_allgenes.csv"), row.names =F)
  write.table (res_prot_ranked, file = paste0(comparisons[1], "_vs_", comparisons[2], "_rank.rnk"), sep = "\t", row.names = F, quote = F)
  
  writeLines( paste0("For the comparison: ", comparisons[1], "_vs_", comparisons[2], ", out of ", nrow(combined_data), " genes, there were: \n", 
               nrow(de_genes_rawp), " genes below p-value ", rawpcutoff, "\n",
               nrow(de_genes_fdr), " genes below padj ", fdrcutoff, "\n",
               nrow(de_genes_log2f), " genes below padj ", fdrcutoff, " and above a log2FoldChange of ", log2cutoff, "\n",
               nrow(de_genes_cpm), " genes below padj ", fdrcutoff, " and above an avg cpm of ", cpmcutoff, "\n",
               "Differential expression gene lists ordered by log2fchange with the cutoffs above have been generated.") )
  gene_count <- tibble (cutoff_parameter = c("pvalue", "padj", "log2fc", "avg_cpm" ), 
                        cutoff_value = c(rawpcutoff, fdrcutoff, log2cutoff, cpmcutoff), 
                        signif_genes = c(nrow(de_genes_rawp), nrow(de_genes_fdr), nrow(de_genes_log2f), nrow(de_genes_cpm)))
  invisible(gene_count)
}

lncap_output <- generate_DE_results (lncap, c("LNCAP_Hypoxia", "LNCAP_Normoxia"))
pc3_output <- generate_DE_results(pc3, c("PC3_Hypoxia", "PC3_Normoxia"))

lncap_output
pc3_output
```

### exploring the results ouptut

Explain column by column and how we got it from the above code

```{r}
res <- read.csv ("LNCAP_Hypoxia_vs_LNCAP_Normoxia_allgenes.csv", header = T)
res
```


## Visualizations

### Differential gene heatmap


```{r}
DE_gene_heatmap <- function(res, padj_cutoff = 0.0001, ngenes = 20) {
  brewer_palette <- "RdBu"
  # Ramp the color in order to get the scale.
  ramp <- colorRampPalette(brewer.pal(11, brewer_palette))
  mr <- ramp(256)[256:1]
  significant_genes <- res %>% filter(padj < padj_cutoff) %>% arrange (desc(log2FoldChange)) %>% head (ngenes)
  heatmap_values <- as.matrix(significant_genes[,-c(1:8)])
  rownames(heatmap_values) <- significant_genes$Gene.name
  pheatmap(heatmap_values, color = mr, scale = "row", fontsize_col = 10, fontsize_row = 200/ngenes, fontsize = 5, border_color = NA)
}
DE_gene_heatmap(res, 0.001, 30)

```






## Conclusion