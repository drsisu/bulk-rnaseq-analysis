---
title: "Bulk RNA-seq data processing and differential gene expression analysis pipeline"
author: Erick Lu
output: 
  html_document:
    toc: true
---

## Introduction

Here, I present a complete bulk RNA-sequencing pipeline, including:

1. Finding and downloading the raw data using SRA tools
2. Mapping FASTQ files using STAR
3. Differential gene analysis using DESeq2
4. Visualizations for Bulk RNA-sequencing


## Obtaining the raw data

### Data repository at GSE106305

The raw data is available at: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE106305. There are several samples associated with this study, and we will only be focusing on the following samples:

Sample Name | GSM Identifier | SRA Identifier (SRX) | SRA Runs (SRR, download these)
------------------ | ----------------- | -------------------------- | --------------------------------------------------------
LNCaP_RNA-Seq_Empty_Vector_Normoxia_rep1 | GSM3145509 | SRX4096735 | SRR7179504, SRR7179505, SRR7179506, and SRR7179507
LNCaP_RNA-Seq_Empty_Vector_Normoxia_rep2 | GSM3145510 | SRX4096736 | SRR7179508, SRR7179509, SRR7179510, and SRR7179511
LNCaP_RNA-Seq_Empty_Vector_Hypoxia_rep1 | GSM3145513 | SRX4096739 | SRR7179520, SRR7179521, SRR7179522, and SRR7179523
LNCaP_RNA-Seq_Empty_Vector_Hypoxia_rep2 | GSM3145514 | SRX4096740 | SRR7179524, SRR7179525, SRR7179526, and SRR7179527
PC3_RNA-Seq_siCtrl_Normoxia_rep1 | GSM3145517 | SRX4096743 | SRR7179536
PC3_RNA-Seq_siCtrl_Normoxia_rep2 | GSM3145518 | SRX4096744 | SRR7179537
PC3_RNA-Seq_siCtrl_Hypoxia_rep1 | GSM3145521 | SRX4096747 | SRR7179540
PC3_RNA-Seq_siCtrl_Hypoxia_rep2 | GSM3145522 | SRX4096748 | SRR7179541

We have selected the control samples for both cell lines (Empty Vector for LNCaP and siCtrl for PC3) in conditions of either normoxia or hypoxia. This will allow us to analyze the LNCaP and PC3 cell lines for their gene expression changes in response to hypoxia, and compare which pathways are commonly upregulated/downregulated by both lines.

Each of the samples above have an associated SRA accession number, indicated above. These SRA accessions are used to download the raw sequencing data. To eventually get the raw data in FASTQ format, we first need to first download the SRA files (`.sra`) associated with each sample.

### Downloading FASTQ files using SRA toolkit

In order to download the SRA files onto your machine, we use the NCBI's SRA toolkit, which lets us use the command line to download a specified SRA accession ID. You can read more about SRA toolkit here: https://www.ncbi.nlm.nih.gov/books/NBK242621/.

The toolkit works by first using the `prefetch` command to download the SRA file associated with the specified SRA ID. The SRA file contains a set of "instructions" for downloading the sequencing data associated with the SRA ID from NCBI. A sample command would be: `prefetch SRR7179504`. This will download the file `SRR7179504.sra` into your home directory at ~/ncbi/public/sra/.

After you have downloaded the SRA file, you can use `fastq-dump` to extract the contents of it into a `.fastq` file. The Edwards lab at SDSU provides a nice tutorial for how to use fastq-dump here: https://edwards.sdsu.edu/research/fastq-dump/. A sample command would be: 

```bash
fastq-dump --outdir fastq --gzip --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip ~/ncbi/public/sra/SRR7179504.sra
```

Since there are lots of SRA files associated with our samples, it would take a long time to manually run `prefetch` and `fastq-dump` for all the files. To automate all the downloads, I wrote a small script in python to call `fastq-dump` on each of the SRA IDs we want. The code is shown below as well as provided in this repo as `fastq_download.py`:

```py
import subprocess

sra_numbers = [
    "SRR7179504", "SRR7179505", "SRR7179506", "SRR7179507",
    "SRR7179508", "SRR7179509", "SRR7179510", "SRR7179511",
    "SRR7179520", "SRR7179521", "SRR7179522", "SRR7179523",
    "SRR7179524", "SRR7179525", "SRR7179526", "SRR7179527",
    "SRR7179536", "SRR7179537", "SRR7179540","SRR7179541"
    ]

# this will download the .sra files to ~/ncbi/public/sra/ (will create directory if not present)
for sra_id in sra_numbers:
    print ("Currently downloading: " + sra_id)
    prefetch = "prefetch " + sra_id
    print ("The command used was: " + prefetch)
    subprocess.call(prefetch, shell=True)

# this will extract the .sra files from above into a folder named 'fastq'
for sra_id in sra_numbers:
    print ("Generating fastq for: " + sra_id)
    fastq_dump = "fastq-dump --outdir fastq --gzip --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip ~/ncbi/public/sra/" + sra_id + ".sra"
    print ("The command used was: " + fastq_dump)
    subprocess.call(fastq_dump, shell=True)
```

We can run the python script by simply navigating to the folder on your machine where you want to store the fastq files (via the command line), then running `python fastq_download.py`. This should work in python 2 and python 3. After running the python script, our .fastq files should all be sitting in a directory called 'fastq'.

### Concatenating FASTQ files

For samples such as LNCaP_RNA-Seq_Empty_Vector_Normoxia_rep1, there are four resulting fastq files containing the sequencing data. We can concatenate these four files into one file by using `cat` in the command line and storing the output into a new fastq file. Below, I perform the concatenation for each of the LNCaP samples, and :

```bash
cat SRR7179504_pass.fastq.gz SRR7179505_pass.fastq.gz SRR7179506_pass.fastq.gz SRR7179507_pass.fastq.gz  > LNCAP_Normoxia_S1.fastq.gz
cat SRR7179508_pass.fastq.gz SRR7179509_pass.fastq.gz SRR7179510_pass.fastq.gz SRR7179511_pass.fastq.gz  > LNCAP_Normoxia_S2.fastq.gz
cat SRR7179520_pass.fastq.gz SRR7179521_pass.fastq.gz SRR7179522_pass.fastq.gz SRR7179523_pass.fastq.gz  > LNCAP_Hypoxia_S1.fastq.gz
cat SRR7179524_pass.fastq.gz SRR7179525_pass.fastq.gz SRR7179526_pass.fastq.gz SRR7179527_pass.fastq.gz  > LNCAP_Hypoxia_S2.fastq.gz
```

In contrast, there is only one fastq file for each of the PC3 samples. We can just rename them from their SRR identifiers to their real sample names using `mv`:

```bash
mv SRR7179536_pass.fastq.gz PC3_Normoxia_S1.fastq.gz
mv SRR7179537_pass.fastq.gz PC3_Normoxia_S2.fastq.gz
mv SRR7179540_pass.fastq.gz PC3_Hypoxia_S1.fastq.gz
mv SRR7179541_pass.fastq.gz PC3_Hypoxia_S2.fastq.gz
```

## Aligning reads using STAR

Each read in your fastq file must be "mapped" to a reference genome. Mapping can be described as finding the place in the reference genome that best matches the fragment of an mRNA transcript captured in the read. In this section, I will describe the concepts behind mapping reads to a reference genome, and how to do it using the tool STAR and some python scripting.

### The concepts behind mapping reads

In order to perform bulk RNA-sequencing, a "library" must first be prepared from the cells of interest and this library is what is sequenced to create the fastq files. To create a library, mRNA from the cells is captured and reverse transcribed into cDNA. This is then fragmented into small pieces, and sequencing adaptors are ligated to the ends of each fragment to create the "library". The resulting fastq file contains the sequences of all these tiny little fragments. Using the sequence for each fragment (a "read"), we can then try to figure out from which part of the genome that fragment came from, and subsequently which gene was being transcribed to create the original mRNA that was captured. Counting the number of times a "read" mapped to a specific gene gives us information about how "high" or "low" a gene was being expressed.

### STAR

A great RNA-seq alignment tool is STAR (Spliced Transcripts Alignment to a Reference, https://github.com/alexdobin/STAR). In order to install STAR, follow the installation instructions provided in the github repo for the platform you are using.

#### building human genome index using genomeGenerate

Once STAR is installed, we first need to build a genome index. In our case, we need to use the human reference genome since we are analyzing RNA-seq data from human cells. We have to supply STAR with the human reference genome sequence (FASTA) and annotation (GTF) files, from which STAR will make genome index files.

We can download the FASTA and GTF files from the ensembl website (https://uswest.ensembl.org/Homo_sapiens/Info/Index) or using the command line:

```bash
wget ftp://ftp.ensembl.org/pub/release-99/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz
wget ftp://ftp.ensembl.org/pub/release-99/gtf/homo_sapiens/Homo_sapiens.GRCh38.99.gtf.gz
gunzip *.gz
```

Once these are downloaded and unzipped, we can run the STAR genomeGenerate command below to make the genome index file. For the genomeDir parameter, you can specify the directory where you are keeping the FASTA and GTF files.

```bash
STAR --runThreadN 64 --runMode genomeGenerate --genomeDir /data/genomes/h38/STAR/ --genomeFastaFiles /data/genomes/h38/STAR/Homo_sapiens.GRCh38.dna.primary_assembly.fa --sjdbGTFfile /data/genomes/h38/STAR/Homo_sapiens.GRCh38.99.gtf
```

The output from successfully running the command looks like:

```{}
Feb 15 20:06:34 ..... started STAR run
Feb 15 20:06:34 ... starting to generate Genome files
Feb 15 20:07:28 ... starting to sort Suffix Array. This may take a long time...
Feb 15 20:07:41 ... sorting Suffix Array chunks and saving them to disk...
Feb 15 20:20:11 ... loading chunks from disk, packing SA...
Feb 15 20:21:15 ... finished generating suffix array
Feb 15 20:21:15 ... generating Suffix Array index
Feb 15 20:25:16 ... completed Suffix Array index
Feb 15 20:25:16 ..... processing annotations GTF
Feb 15 20:25:26 ..... inserting junctions into the genome indices
Feb 15 20:27:58 ... writing Genome to disk ...
Feb 15 20:28:01 ... writing Suffix Array to disk ...
Feb 15 20:28:18 ... writing SAindex to disk
Feb 15 20:28:20 ..... finished successfully
```

After running the command, you should see a bunch of genome index files in the directory specified by genomeDir. Now, we can start mapping reads from our FASTQ files, which I will explain in the next section.

#### mapping reads

An example STAR command used to map a single sample, LNCAP_Normoxia_S1_R1_001.fastq.gz, to the reference genome that we just built is:

```bash
STAR --runThreadN 64 --genomeDir /data/genomes/h38/STAR --outFilterType BySJout --outFilterMismatchNoverLmax 0.04 --outFilterMismatchNmax 999 --alignSJDBoverhangMin 1 --alignSJoverhangMin 8 --outFilterMultimapNmax 20 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --readFilesIn /fastq/LNCAP_Normoxia_S1_R1_001.fastq.gz --clip3pAdapterSeq GATCGGAAGAGCACACGTCTGAACTCCAGTCAC --outSAMtype BAM SortedByCoordinate --quantMode GeneCounts --outFileNamePrefix LNCAP_Normoxia_S1
```
Notice that I've plugged in the directory that contains the genome index files for `--genomeDir`, as well as the fastq file location for sample LNCAP_Normoxia_S1_R1_001.fastq.gz for `--readFilesIn` and also provided the sample name for `--outFileNamePrefix`.

#### using python to map reads for all samples

## Performing Differential Gene Expression Analysis

## Conclusion